{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ee65faa-5aa5-416b-b80c-839c4f455c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde210bf-0227-462f-98d6-5c9891711a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: A woman goes under a horse.\n",
      "Tokenized: ['a', 'woman', 'goes', 'under', 'a', 'horse.']\n",
      "Numericalized: [4, 7, 18, 12, 4, 20]\n",
      "Max caption length: 42\n",
      "Batch video features shape: torch.Size([10, 80, 4096])\n",
      "Batch captions shape: torch.Size([10, 42])\n"
     ]
    }
   ],
   "source": [
    "# laod JSON\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# clean and tokenize captions\n",
    "def clean_caption(caption):\n",
    "    tokens = caption.lower().split()\n",
    "    return tokens\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, freq_threshold):\n",
    "        self.itos = {0: \"<PAD>\", 1: \"<BOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.stoi = {v: k for k, v in self.itos.items()}\n",
    "        self.freq_threshold = freq_threshold\n",
    "        \n",
    "    def get_vocab_size(self):\n",
    "        return len(self.stoi)\n",
    "\n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        frequencies = Counter()\n",
    "        idx = 4  \n",
    "        for sentence in sentence_list:\n",
    "            for word in sentence:\n",
    "                frequencies[word] += 1\n",
    "            \n",
    "                if frequencies[word] == self.freq_threshold:\n",
    "                    self.stoi[word] = idx\n",
    "                    self.itos[idx] = word\n",
    "                    idx += 1\n",
    "\n",
    "    def numericalize(self, text):\n",
    "        tokenized_text = clean_caption(text)\n",
    "        return [\n",
    "            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"]\n",
    "            for token in tokenized_text\n",
    "        ]\n",
    "\n",
    "class VideoCaptionDataset(Dataset):\n",
    "    def __init__(self, features_dir, annotations, vocab, max_length, transform=None):\n",
    "        self.features_dir = features_dir\n",
    "        self.annotations = annotations\n",
    "        self.vocab = vocab\n",
    "        self.max_length = max_length\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        caption_data = self.annotations[index]\n",
    "        caption_list = caption_data['caption']\n",
    "        img_id = caption_data['id']\n",
    "        img_path = f\"{self.features_dir}/{img_id}.npy\"\n",
    "        video_features = np.load(img_path)\n",
    "        if index == 0:\n",
    "            print(f\"Example video features shape: {video_features.shape}\")\n",
    "        \n",
    "        #random caption for training\n",
    "        caption = np.random.choice(caption_list)\n",
    "        numericalized_caption = [self.vocab.stoi[\"<BOS>\"]] + self.vocab.numericalize(caption) + [self.vocab.stoi[\"<EOS>\"]]\n",
    "        padded_caption = numericalized_caption + [self.vocab.stoi[\"<PAD>\"]] * (self.max_length - len(numericalized_caption))\n",
    "\n",
    "        #print(f\"Random caption: {caption}\")\n",
    "        #print(f\"Original caption length (including <BOS> and <EOS>): {len(numericalized_caption)}\")\n",
    "        #print(f\"Padded caption length: {len(padded_caption)}\")\n",
    "        #print(f\"Padded caption: {padded_caption}\")\n",
    "        #print(f\"Video ID: {img_id}\")\n",
    "        #print(f\"Selected Caption: {caption}\")\n",
    "        #print(f\"Numericalized Caption: {numericalized_caption}\")\n",
    "        #print(f\"Padded Caption: {padded_caption}\")\n",
    "        #print(f\"Video Feature Path: {img_path}\")\n",
    "        \n",
    "        if self.transform:\n",
    "            video_features = self.transform(video_features)\n",
    "\n",
    "        return torch.tensor(video_features, dtype=torch.float), torch.tensor(padded_caption, dtype=torch.long)\n",
    "\n",
    "def generate_caption(model, video_features, vocab, max_length):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_ids = torch.tensor([vocab.stoi[\"<BOS>\"]], device=video_features.device)\n",
    "        outputs = model(video_features, input_ids)\n",
    "        \n",
    "        generated_caption_indices = []\n",
    "        \n",
    "        for i in range(max_length):\n",
    "            # forwar pass\n",
    "            #print('input id ', input_ids)\n",
    "            #outputs = model(video_features, input_ids)\n",
    "            #print(max_length)\n",
    "            #print(f'outputs shape: {outputs.shape}')\n",
    "            # use last word for sequence\n",
    "            next_word_id = outputs[0, i].argmax(0)\n",
    "                #print(f\"next_word_id: {next_word_id}\")\n",
    "                #print(f\"next_word_id: {next_word_id.item()}\")\n",
    "            if next_word_id == vocab.stoi[\"<EOS>\"]:\n",
    "                break\n",
    "            \n",
    "            generated_caption_indices.append(next_word_id.item())\n",
    "            input_ids = torch.cat([input_ids, next_word_id.unsqueeze(0)])  \n",
    "        generated_caption = ' '.join([vocab.itos[idx] for idx in generated_caption_indices if idx in vocab.itos])\n",
    "    return generated_caption\n",
    "\n",
    "\n",
    "# train files\n",
    "features_dir = '../S2VT_assignment/MLDS_hw2_1_data/training_data/feat'\n",
    "training_data = load_json('../S2VT_assignment/MLDS_hw2_1_data/training_label.json')\n",
    "\n",
    "# flatten captions\n",
    "all_captions = [caption for item in training_data for caption in item['caption']]\n",
    "\n",
    "# token the captions \n",
    "tokenized_captions = [clean_caption(caption) for caption in all_captions]\n",
    "#print(tokenized_captions)\n",
    "\n",
    "# build the vocab w/ threshold\n",
    "vocab = Vocabulary(freq_threshold=3)\n",
    "vocab.build_vocabulary(tokenized_captions)\n",
    "caption_example = training_data[0]['caption'][0]\n",
    "tokens_example = clean_caption(caption_example)\n",
    "numericalized_example = vocab.numericalize(caption_example)\n",
    "print(f\"Original: {caption_example}\")\n",
    "print(f\"Tokenized: {tokens_example}\")\n",
    "print(f\"Numericalized: {numericalized_example}\")\n",
    "\n",
    "\n",
    "# create max length for caption padding\n",
    "max_caption_length = max(len(clean_caption(c)) for c in all_captions) + 2\n",
    "print(f\"Max caption length: {max_caption_length}\")\n",
    "\n",
    "dataset = VideoCaptionDataset(features_dir, training_data, vocab, max_caption_length)\n",
    "data_loader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# checking\n",
    "for video_features, captions in data_loader:\n",
    "    print(f\"Batch video features shape: {video_features.shape}\")\n",
    "    print(f\"Batch captions shape: {captions.shape}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58be2095-5250-4b1b-a18f-1a12bfcd3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print vocab\n",
    " #   print(f\"{word}: {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc6f7b29-0935-4410-9aa5-4a8769c95270",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S2VTModel(nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim, vocab_size, max_seq_length=41):\n",
    "        super(S2VTModel, self).__init__()\n",
    "        self.encoder_lstm = nn.LSTM(feature_dim, hidden_dim, batch_first=True, num_layers=2, dropout=0.3)\n",
    "        \n",
    "        self.decoder_lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, num_layers=2, dropout=0.3)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def forward(self, video_features, captions=None):\n",
    "        # encoding\n",
    "        _, (hidden, _) = self.encoder_lstm(video_features)\n",
    "\n",
    "        # decoding\n",
    "        outputs = []\n",
    "        step_input = torch.zeros(video_features.size(0), 1, hidden.size(2)).to(video_features.device)\n",
    "        for _ in range(self.max_seq_length):\n",
    "            output, (hidden, _) = self.decoder_lstm(step_input, (hidden, hidden))\n",
    "            step_input = output\n",
    "            output = self.fc(output.squeeze(1))\n",
    "            outputs.append(output)\n",
    "        outputs = torch.stack(outputs, 1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4046ed33-81fb-4e7a-8386-10d9d57d5a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2VTModel(\n",
      "  (encoder_lstm): LSTM(4096, 500, num_layers=2, batch_first=True, dropout=0.3)\n",
      "  (decoder_lstm): LSTM(500, 500, num_layers=2, batch_first=True, dropout=0.3)\n",
      "  (fc): Linear(in_features=500, out_features=3529, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size = vocab.get_vocab_size() \n",
    "feature_dim = 4096 #this is preset by input features, change for TA test?\n",
    "hidden_dim = 500\n",
    "model = S2VTModel(feature_dim, hidden_dim, vocab_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afeeb545-f974-48e2-8327-11d3c4984726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use cuda, set up model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# set optimzer and criterion\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab.stoi[\"<PAD>\"])\n",
    "#scheduler = StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "#some variables\n",
    "num_epochs = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b31b2de-cab9-433e-9b5e-ff016d3ed2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74a3c3b6-7b28-40b0-a5ca-b4e435358ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Predicted: ['steel', 'place.', 'place.', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'dialing', 'dialing', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training', 'training']\n",
      "Ground Truth: ['a', 'person', 'is', 'mixing', 'a', '<UNK>', 'mixture', 'in', 'a', 'glass', 'bowl', 'with', 'a', 'wooden', 'spoon.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [1/75], Loss: 5.803582346028295\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [2/75], Loss: 4.6855193466975775\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [3/75], Loss: 4.534330414081442\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [4/75], Loss: 4.460736786085984\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [5/75], Loss: 4.504887755163785\n",
      "Epoch: 6\n",
      "Predicted: ['a', 'man', 'is', 'a', 'a', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "Ground Truth: ['the', 'lady', 'sliced', 'the', 'onion.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [6/75], Loss: 4.413940063016168\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [7/75], Loss: 4.388809916068768\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [8/75], Loss: 4.3732017122465985\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [9/75], Loss: 4.337825553170566\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [10/75], Loss: 4.310928739350418\n",
      "Epoch: 11\n",
      "Predicted: ['a', 'man', 'is', 'a', 'a', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "Ground Truth: ['a', 'person', 'is', 'driving', 'a', 'motorcycle', 'down', 'a', 'highway.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [11/75], Loss: 4.322865218129651\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [12/75], Loss: 4.288013507579935\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [13/75], Loss: 4.22927302492076\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [14/75], Loss: 4.234701487113689\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [15/75], Loss: 4.180413061996986\n",
      "Epoch: 16\n",
      "Predicted: ['a', 'woman', 'is', 'a', 'a', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "Ground Truth: ['the', 'man', 'is', 'pouring', 'water', 'into', 'the', 'pan', 'filled', 'with', 'rice.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [16/75], Loss: 4.1567751111655395\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [17/75], Loss: 4.1115104527309025\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [18/75], Loss: 4.125178583737077\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [19/75], Loss: 4.11269278197453\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [20/75], Loss: 4.042406744792544\n",
      "Epoch: 21\n",
      "Predicted: ['a', 'are', 'are', 'playing', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "Ground Truth: ['five', 'women', 'throw', 'their', 'pom', 'poms', 'in', 'the', 'air.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [21/75], Loss: 3.9776886265853357\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [22/75], Loss: 3.973788384733529\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [23/75], Loss: 3.9836045857133535\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [24/75], Loss: 3.9528731510556976\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [25/75], Loss: 3.9421298027038576\n",
      "Epoch: 26\n",
      "Predicted: ['a', 'dog', 'is', 'a', 'a', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "Ground Truth: ['a', 'car', 'is', 'pulling', 'up', 'to', 'a', '<UNK>', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [26/75], Loss: 3.9054262522993417\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [27/75], Loss: 3.901578261934478\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [28/75], Loss: 3.906692544345198\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [29/75], Loss: 3.945643392102472\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [30/75], Loss: 3.855091823380569\n",
      "Epoch: 31\n",
      "Predicted: ['a', 'man', 'is', 'a', 'a', 'a', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "Ground Truth: ['a', 'man', 'is', 'breaking', 'a', 'vase', 'on', 'a', 'teenage', \"boy's\", 'head.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [31/75], Loss: 3.8641403411996778\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [32/75], Loss: 3.8172204987756135\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [33/75], Loss: 3.773156664289277\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [34/75], Loss: 3.8017524028646537\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [35/75], Loss: 3.8150212353673476\n",
      "Epoch: 36\n",
      "Predicted: ['a', 'woman', 'is', 'a', 'a', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "Ground Truth: ['a', 'woman', 'is', 'wrapping', 'rice', 'in', 'paper.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [36/75], Loss: 3.7819733767673887\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [37/75], Loss: 3.785301685333252\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [38/75], Loss: 3.7277314893130598\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [39/75], Loss: 3.734106317059747\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [40/75], Loss: 3.7401877633456526\n",
      "Epoch: 41\n",
      "Predicted: ['a', 'man', 'is', 'a', 'a', 'a', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "Ground Truth: ['a', 'car', 'is', '<UNK>', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [41/75], Loss: 3.674883413314819\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [42/75], Loss: 3.692082005533679\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [43/75], Loss: 3.687147776833896\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [44/75], Loss: 3.670852707172262\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [45/75], Loss: 3.678119106950431\n",
      "Epoch: 46\n",
      "Predicted: ['a', 'panda', 'is', 'a', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "Ground Truth: ['an', 'umbrella', 'is', 'floating', 'in', 'the', 'water.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [46/75], Loss: 3.6756752819850527\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [47/75], Loss: 3.6306316211305814\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [48/75], Loss: 3.6020616416273445\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [49/75], Loss: 3.633739685190135\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [50/75], Loss: 3.6086940420084987\n",
      "Epoch: 51\n",
      "Predicted: ['a', 'little', 'is', 'is', 'a', 'a', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "Ground Truth: ['a', 'puppet', 'is', 'talking', 'on', 'a', 'telephone.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [51/75], Loss: 3.5741526455714783\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [52/75], Loss: 3.5671993765337713\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [53/75], Loss: 3.598398516095918\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [54/75], Loss: 3.5667272830831593\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [55/75], Loss: 3.6004696632253714\n",
      "Epoch: 56\n",
      "Predicted: ['a', 'are', 'are', 'a', 'a', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "Ground Truth: ['men', 'are', 'running', 'a', 'race.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [56/75], Loss: 3.5310418934657655\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [57/75], Loss: 3.5406238391481595\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [58/75], Loss: 3.4840489601266795\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [59/75], Loss: 3.5512613987100536\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [60/75], Loss: 3.515409630742566\n",
      "Epoch: 61\n",
      "Predicted: ['three', 'are', 'are', 'dancing.', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "Ground Truth: ['three', 'women', 'are', 'performing', 'on', 'a', 'stage.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [61/75], Loss: 3.4676109955228607\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [62/75], Loss: 3.5620267062351623\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [63/75], Loss: 3.446429132593089\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [64/75], Loss: 3.5081855757483122\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [65/75], Loss: 3.5010766160899194\n",
      "Epoch: 66\n",
      "Predicted: ['a', 'man', 'is', 'a', 'a', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "Ground Truth: ['a', 'man', 'is', 'eating', 'a', 'banana.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [66/75], Loss: 3.4374058065743283\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [67/75], Loss: 3.431068726243644\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [68/75], Loss: 3.4746402460953285\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [69/75], Loss: 3.4134341996291586\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [70/75], Loss: 3.4074864321741565\n",
      "Epoch: 71\n",
      "Predicted: ['a', 'man', 'is', 'playing', 'a', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "Ground Truth: ['a', 'man', 'plays', 'a', 'string', 'instrument.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [71/75], Loss: 3.4365795283481995\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [72/75], Loss: 3.4291307021831643\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [73/75], Loss: 3.3711363775976775\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [74/75], Loss: 3.3786197169073695\n",
      "Example video features shape: (80, 4096)\n",
      "Epoch [75/75], Loss: 3.4277625906056373\n"
     ]
    }
   ],
   "source": [
    "epoch_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (video_features, captions) in enumerate(data_loader):\n",
    "        video_features, captions = video_features.to(device), captions.to(device)\n",
    "    \n",
    "        # forward pass\n",
    "        outputs = model(video_features, captions[:, :-1])\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), captions[:, 1:].reshape(-1))\n",
    "        \n",
    "        #see predictions for model progress\n",
    "        if batch_idx == 0 and (epoch % 5 == 0):\n",
    "            print(\"Epoch:\", epoch + 1)\n",
    "            logits = outputs[0, :, :]\n",
    "            predicted_indices = logits.argmax(dim=1)\n",
    "            predicted_tokens = [vocab.itos[idx.item()] for idx in predicted_indices]\n",
    "            \n",
    "            # ground truth\n",
    "            ground_truth_indices = captions[0, 1:]\n",
    "            ground_truth_tokens = [vocab.itos[idx.item()] for idx in ground_truth_indices]\n",
    "            \n",
    "            print(\"Predicted:\", predicted_tokens)\n",
    "            print(\"Ground Truth:\", ground_truth_tokens)\n",
    "        \n",
    "        # optimze, backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        #scheduler.step()\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        epoch_losses.append(avg_loss)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb05ce9b-2580-4ea7-a553-cfb31fc1c83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "epochs = range(1, len(epoch_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, epoch_losses, marker='o', label='Training Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90da7c29-a054-4e97-ad12-44144cb3cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"s2vt3_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e4b2f53-8833-4f96-b1aa-3e43b312a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoCaptionDatasetTest(Dataset):\n",
    "    def __init__(self, features_dir, annotations):\n",
    "        self.features_dir = features_dir\n",
    "        self.annotations = annotations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.annotations[index]['id']\n",
    "        img_path = f\"{self.features_dir}/{img_id}.npy\"\n",
    "        test_video_features = np.load(img_path)\n",
    "\n",
    "        return torch.tensor(test_video_features, dtype=torch.float), img_id\n",
    "\n",
    "#test annotations\n",
    "test_annotations = load_json('../S2VT_assignment/MLDS_hw2_1_data/testing_label.json')\n",
    "\n",
    "# test dataset and loader\n",
    "test_dataset = VideoCaptionDatasetTest('../S2VT_assignment/MLDS_hw2_1_data/testing_data/feat', test_annotations)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "max_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b13bd6f-72a9-4b0c-94ec-6007fcf4232a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S2VTModel(\n",
       "  (encoder_lstm): LSTM(4096, 500, num_layers=2, batch_first=True, dropout=0.3)\n",
       "  (decoder_lstm): LSTM(500, 500, num_layers=2, batch_first=True, dropout=0.3)\n",
       "  (fc): Linear(in_features=500, out_features=3529, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = S2VTModel(feature_dim, hidden_dim, vocab_size)\n",
    "model.load_state_dict(torch.load(\"s2vt3_model.pth\", map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb54d219-f6bb-45db-b990-706a6acc9c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video file path: ScdUht-pM6s_53_63.avi\n",
      "Ground truth caption: The man is putting flour on the chicken.\n",
      "Generated caption: a woman is a a\n",
      "Video file path: wkgGxsuNVSg_34_41.avi\n",
      "Ground truth caption: A child is running from a fish.\n",
      "Generated caption: a monkey is a a a\n",
      "Video file path: BtQtRGI0F2Q_15_20.avi\n",
      "Ground truth caption: Two people are working on a power line and one of them is electrocuted.\n",
      "Generated caption: a <UNK> is a a the\n",
      "Video file path: k06Ge9ANKM8_5_16.avi\n",
      "Ground truth caption: A dog is popping balloons with its teeth.\n",
      "Generated caption: a baby is is\n",
      "Video file path: sZf3VDsdDPM_107_114.avi\n",
      "Ground truth caption: A man chews food with a pitiable expression while the woman appreciates the food she is eating.\n",
      "Generated caption: a man is a a\n",
      "Video file path: shPymuahrsc_5_12.avi\n",
      "Ground truth caption: The mammal sniffed at the bowl of food.\n",
      "Generated caption: a animal is eating a\n",
      "Video file path: XOAgUVVwKEA_8_20.avi\n",
      "Ground truth caption: The girl ate spaghetti from her high chair.\n",
      "Generated caption: a baby is is a\n",
      "Video file path: ufFT2BWh3BQ_0_8.avi\n",
      "Ground truth caption: The baby pandas are playing.\n",
      "Generated caption: a panda panda is on a\n",
      "Video file path: 5YJaS2Eswg0_22_26.avi\n",
      "Ground truth caption: A girl is skipping rope.\n",
      "Generated caption: a man is riding a a\n",
      "Video file path: lw7pTwpx0K0_38_48.avi\n",
      "Ground truth caption: A man screws a wave guide on the groove of a compression driver.\n",
      "Generated caption: a man is cutting a\n",
      "Video file path: UbmZAe5u5FI_132_141.avi\n",
      "Ground truth caption: A woman is removing bones from a fish.\n",
      "Generated caption: a person is a a\n",
      "Video file path: xCFCXzDUGjY_5_9.avi\n",
      "Ground truth caption: A man is skateboarding and falls.\n",
      "Generated caption: a man is a a the\n",
      "Video file path: He7Ge7Sogrk_47_70.avi\n",
      "Ground truth caption: An elephant is drawing with its trunk.\n",
      "Generated caption: a man is a a a\n",
      "Video file path: tJHUH9tpqPg_113_118.avi\n",
      "Ground truth caption: A woman is juicing a lemon.\n",
      "Generated caption: a woman is a a\n",
      "Video file path: n016q1w8Q30_2_11.avi\n",
      "Ground truth caption: A man is doing a card trick.\n",
      "Generated caption: a man is cutting a\n",
      "Video file path: RjpbFlOHFps_8_25.avi\n",
      "Ground truth caption: The building exploded.\n",
      "Generated caption: a <UNK> is a a the\n",
      "Video file path: 6JnGBs88sL0_4_10.avi\n",
      "Ground truth caption: A helicopter begins to land on top of a building.\n",
      "Generated caption: a boy is a a a\n",
      "Video file path: EpMuCrbxE8A_107_115.avi\n",
      "Ground truth caption: The rock star performed with his guitar.\n",
      "Generated caption: a man is a a a\n",
      "Video file path: HAjwXjwN9-A_16_24.avi\n",
      "Ground truth caption: Women, with numbers on their backs, are skating in a roller derby.\n",
      "Generated caption: a car is a a a\n",
      "Video file path: 4xVGpDmA4lE_23_33.avi\n",
      "Ground truth caption: A man and woman are walking down a road.\n",
      "Generated caption: a man is a a a\n",
      "Video file path: k5OKBX2e7xA_19_32.avi\n",
      "Ground truth caption: A stunt biker spins around on one wheel.\n",
      "Generated caption: a woman is a a a\n",
      "Video file path: Jag7oTemldY_12_25.avi\n",
      "Ground truth caption: A man is yelling.\n",
      "Generated caption: a man is a a the\n",
      "Video file path: 8MVo7fje_oE_125_130.avi\n",
      "Ground truth caption: A man is putting a lid on a rectangular plastic container.\n",
      "Generated caption: a man is putting a of a\n",
      "Video file path: bqMmyY1ImkI_0_14.avi\n",
      "Ground truth caption: Boys are bathing in the water-tub.\n",
      "Generated caption: a man is a a a\n",
      "Video file path: jTnrm338_KY_34_42.avi\n",
      "Ground truth caption: Someone is putting a lizard into a box.\n",
      "Generated caption: a man is a a\n",
      "Video file path: UdcObAQ5OOM_15_30.avi\n",
      "Ground truth caption: A woman in a ski cap and sunglasses is riding in the back seat of a car talking on a cell phone.\n",
      "Generated caption: a woman is a a a\n",
      "Video file path: 4PcL6-mjRNk_11_18.avi\n",
      "Ground truth caption: The dog brough the ball into the hall.\n",
      "Generated caption: a monkey is a a a\n",
      "Video file path: 3qqEKTPxLNs_1_15.avi\n",
      "Ground truth caption: A baby is placing a pacifier in her mouth.\n",
      "Generated caption: a baby is playing with a\n",
      "Video file path: glrijRGnmc0_211_215.avi\n",
      "Ground truth caption: A man puts a cup in the microwave.\n",
      "Generated caption: a man is cutting a\n",
      "Video file path: q7pOFn8s4zc_263_273.avi\n",
      "Ground truth caption: A man and woman are dancing.\n",
      "Generated caption: a man is a\n",
      "Video file path: mtrCf667KDk_134_176.avi\n",
      "Ground truth caption: A woman is peeling the skin of a ripe papaya using a knife.\n",
      "Generated caption: a woman is cutting a\n",
      "Video file path: 0lh_UWF9ZP4_62_69.avi\n",
      "Ground truth caption: The lady stirred the hot food in the bowl.\n",
      "Generated caption: a woman is cooking a\n",
      "Video file path: JntMAcTlOF0_50_70.avi\n",
      "Ground truth caption: A kid runs up a hill.\n",
      "Generated caption: a man is a a\n",
      "Video file path: 7NNg0_n-bS8_21_30.avi\n",
      "Ground truth caption: A man is singing and playing a guitar.\n",
      "Generated caption: a man is playing a\n",
      "Video file path: IhwPQL9dFYc_124_129.avi\n",
      "Ground truth caption: A woman is slicing some butter.\n",
      "Generated caption: a woman is slicing a\n",
      "Video file path: BAf3LXFUaGs_28_38.avi\n",
      "Ground truth caption: A man is playing the drums.\n",
      "Generated caption: a man is talking\n",
      "Video file path: 6q1dX6thX3E_286_295.avi\n",
      "Ground truth caption: A man is talking on the telephone.\n",
      "Generated caption: a woman is talking\n",
      "Video file path: RZL9irxnhZ0_34_40.avi\n",
      "Ground truth caption: A man is giving an interview to a number of tv reporters.\n",
      "Generated caption: a man is a a\n",
      "Video file path: WWf0Z6ak3Dg_5_15.avi\n",
      "Ground truth caption: A bulldog is playing with a yoga ball.\n",
      "Generated caption: a dog is running the the\n",
      "Video file path: PeUHy0A1GF0_114_121.avi\n",
      "Ground truth caption: Someone is cleaning some shrimp.\n",
      "Generated caption: a woman is a a\n",
      "Video file path: klteYv1Uv9A_27_33.avi\n",
      "Ground truth caption: A man laying down is riding a motorcycle.\n",
      "Generated caption: a man is a a\n",
      "Video file path: e-j59PqJjSM_405_416.avi\n",
      "Ground truth caption: A person stirs a bowl full of food.\n",
      "Generated caption: a man is adding into a a\n",
      "Video file path: 778mkceE0UQ_40_46.avi\n",
      "Ground truth caption: A car is driving down the road.\n",
      "Generated caption: a car is a a the\n",
      "Video file path: 77iDIp40m9E_126_131.avi\n",
      "Ground truth caption: The dog rode a skateboard.\n",
      "Generated caption: a turtle is walking the the\n",
      "Video file path: e-j59PqJjSM_50_98.avi\n",
      "Ground truth caption: A man cuts vegetables.\n",
      "Generated caption: a man is slicing a\n",
      "Video file path: Dgf0VHMEtNs_57_66.avi\n",
      "Ground truth caption: The doctors worked on the patient in the operating room.\n",
      "Generated caption: a woman is a a\n",
      "Video file path: f9Won2JpOEU_60_80.avi\n",
      "Ground truth caption: The cat is cleaning himself.\n",
      "Generated caption: a cat is a a a\n",
      "Video file path: dfOuTx66bJU_34_39.avi\n",
      "Ground truth caption: A man is running.\n",
      "Generated caption: a man is a a a\n",
      "Video file path: 04Gt01vatkk_248_265.avi\n",
      "Ground truth caption: A woman cuts an oion.\n",
      "Generated caption: a woman is cutting a\n",
      "Video file path: rl1rVk_xIOs_1_16.avi\n",
      "Ground truth caption: A baby is dancing.\n",
      "Generated caption: a boy is dancing.\n",
      "Video file path: v7iIZXtpIb8_5_15.avi\n",
      "Ground truth caption: A boy is playing the piano.\n",
      "Generated caption: a man is eating a\n",
      "Video file path: DhwrBs96Kgk_120_124.avi\n",
      "Ground truth caption: A monkey is walking through the water.\n",
      "Generated caption: a woman is a a a\n",
      "Video file path: qLwgb3F0aPU_298_305.avi\n",
      "Ground truth caption: Several men are doing maneuvers as the run across the grass.\n",
      "Generated caption: a are are a\n",
      "Video file path: qeKX-N1nKiM_0_5.avi\n",
      "Ground truth caption: A person pours a sauce over a plate of food.\n",
      "Generated caption: a person is adding a a a\n",
      "Video file path: 1Sp2__RCT0c_11_15.avi\n",
      "Ground truth caption: A rocket explodes in the air.\n",
      "Generated caption: a are is a a a\n",
      "Video file path: Fe4tO5vW9_E_64_70.avi\n",
      "Ground truth caption: A person melts a stick of butter in a pan.\n",
      "Generated caption: a person is stirring a a a\n",
      "Video file path: mmSQTI6gMNQ_120_128.avi\n",
      "Ground truth caption: Two men are staring at women behind a bush.\n",
      "Generated caption: a women are dancing.\n",
      "Video file path: HV12kTtdTT4_5_14.avi\n",
      "Ground truth caption: A cat is watching a movie on a computer monitor.\n",
      "Generated caption: a boy is a a a\n",
      "Video file path: 0lh_UWF9ZP4_27_31.avi\n",
      "Ground truth caption: Someone is slicing a potato.\n",
      "Generated caption: a woman is slicing a\n",
      "Video file path: Je3V7U5Ctj4_569_576.avi\n",
      "Ground truth caption: A person sprinkles shredded cheese on a tortilla.\n",
      "Generated caption: a man is a a\n",
      "Video file path: 30GeJHYoerk_121_126.avi\n",
      "Ground truth caption: A man jumps across a platform on his hands.\n",
      "Generated caption: a man is a a the\n",
      "Video file path: 04Gt01vatkk_308_321.avi\n",
      "Ground truth caption: A woman is dicing peppers.\n",
      "Generated caption: a man is cutting a\n",
      "Video file path: zulPFoY64wE_26_33.avi\n",
      "Ground truth caption: A man is riding a horse.\n",
      "Generated caption: a man is a a a\n",
      "Video file path: MrQd1zUVRUM_103_110.avi\n",
      "Ground truth caption: Two girls passionately kissed.\n",
      "Generated caption: a man is a a\n",
      "Video file path: xxHx6s_DbUo_216_222.avi\n",
      "Ground truth caption: A man is meditating when the scene flashes to a forest, then mountains, and then to a man sliding on ice.\n",
      "Generated caption: a man is a a a\n",
      "Video file path: 71soiLO6I9U_15_24.avi\n",
      "Ground truth caption: A hedgehog is digging underneath its house.\n",
      "Generated caption: a person is a a\n",
      "Video file path: UXs3eq68ZjE_250_255.avi\n",
      "Ground truth caption: Someone is mixing ingrediants.\n",
      "Generated caption: a is is adding a a a\n",
      "Video file path: jbzaMtPYtl8_48_58.avi\n",
      "Ground truth caption: Men are rolling big tyre.\n",
      "Generated caption: a man is a a a\n",
      "Video file path: 8HB7ywgJuTg_131_142.avi\n",
      "Ground truth caption: A person puts a mixture in a pan and stirs it.\n",
      "Generated caption: a woman is frying a\n",
      "Video file path: Cjf21Y19aUQ_82_86.avi\n",
      "Ground truth caption: A man takes off his sunglasses.\n",
      "Generated caption: a man is a a\n",
      "Video file path: qvg9eM4Hmzk_4_10.avi\n",
      "Ground truth caption: A man is lifting the rear end of a truck up into the air.\n",
      "Generated caption: a man is a a a\n",
      "Video file path: 5HAf_INrFy0_3_25.avi\n",
      "Ground truth caption: A cat is swiping at a television.\n",
      "Generated caption: a girl is a a\n",
      "Video file path: YmXCfQm0_CA_277_284.avi\n",
      "Ground truth caption: A snake is slithering on leaves.\n",
      "Generated caption: a man is a a <UNK>\n",
      "Video file path: 88DOMJ11q2M_84_87.avi\n",
      "Ground truth caption: The woman dove into the pool.\n",
      "Generated caption: a woman is a\n",
      "Video file path: NUYu9c9XsgY_7_21.avi\n",
      "Ground truth caption: A person types on a keyboard.\n",
      "Generated caption: a man is a a\n",
      "Video file path: N3A7944_UJw_63_70.avi\n",
      "Ground truth caption: A man is cooking food on a large frying pan.\n",
      "Generated caption: a man is a a a\n",
      "Video file path: uJPupV4oLZ0_4_12.avi\n",
      "Ground truth caption: The man held a tiny frog in his hand.\n",
      "Generated caption: a woman is a a\n",
      "Video file path: cnsjm3fNEec_4_10.avi\n",
      "Ground truth caption: A man is stuffing himself full with food.\n",
      "Generated caption: a man is a a a\n",
      "Video file path: J_evFB7RIKA_104_120.avi\n",
      "Ground truth caption: A chef removes the pit from a bell pepper.\n",
      "Generated caption: a person is slicing a\n",
      "Video file path: g1Gldu1KS44_8_14.avi\n",
      "Ground truth caption: An elephant walks around.\n",
      "Generated caption: a car is a a the\n",
      "Video file path: s1ZABV7AQdA_38_48.avi\n",
      "Ground truth caption: A large group of people are chasing a man with a briefcase down a road.\n",
      "Generated caption: a are are a\n",
      "Video file path: tcxhOGyrCtI_15_21.avi\n",
      "Ground truth caption: A cat is walking through some grass.\n",
      "Generated caption: a cat is playing a a\n",
      "Video file path: inzk2fTUe1w_1_15.avi\n",
      "Ground truth caption: A person is peeling a banana.\n",
      "Generated caption: a man is a a\n",
      "Video file path: j2Dhf-xFUxU_13_20.avi\n",
      "Ground truth caption: A person is slicing some tortillas.\n",
      "Generated caption: a person is slicing a\n",
      "Video file path: MTjrZthHwJQ_2_11.avi\n",
      "Ground truth caption: The dogs raced to get out of the pool.\n",
      "Generated caption: a monkey is a a a\n",
      "Video file path: J---aiyznGQ_0_6.avi\n",
      "Ground truth caption: A cat is playing a key-board.\n",
      "Generated caption: a man is playing a\n",
      "Video file path: ZbtpcGi2DWY_161_170.avi\n",
      "Ground truth caption: The polar bear came down the cliffs.\n",
      "Generated caption: a bird is eating a\n",
      "Video file path: RSx5G0_xH48_12_17.avi\n",
      "Ground truth caption: A little dog is sitting in a room barking at something.\n",
      "Generated caption: a puppy is playing with a\n",
      "Video file path: ecm9gf2Pgkc_1_24.avi\n",
      "Ground truth caption: An animal sniffs around and plays.\n",
      "Generated caption: a man is a a a\n",
      "Video file path: pW9DFPqoIsI_26_50.avi\n",
      "Ground truth caption: Mail is being opened.\n",
      "Generated caption: a man is a a of\n",
      "Video file path: N2Cm0SLr0ZE_18_29.avi\n",
      "Ground truth caption: A child plays the guitar.\n",
      "Generated caption: a boy is playing a\n",
      "Video file path: sJSmRik2c-c_1_7.avi\n",
      "Ground truth caption: A rain is riding on a track.\n",
      "Generated caption: a car is a a a\n",
      "Video file path: zv2RIbUsnSw_335_341.avi\n",
      "Ground truth caption: A woman is riding on a hospital stretcher.\n",
      "Generated caption: a man is a a a\n",
      "Video file path: aM-RcQj0a7I_37_55.avi\n",
      "Ground truth caption: A woman is frying dough in a pan.\n",
      "Generated caption: a person is a a a a\n",
      "Video file path: TZ860P4iTaM_15_28.avi\n",
      "Ground truth caption: A cat is playing a key board.\n",
      "Generated caption: a cat is playing a a\n",
      "Video file path: lo4KcsBN--A_0_10.avi\n",
      "Ground truth caption: A turtle and fishes are swimming under the water.\n",
      "Generated caption: a monkey is a a a\n",
      "Video file path: u4T76jsPin0_0_11.avi\n",
      "Ground truth caption: Some men are running on a track.\n",
      "Generated caption: a man player a a a\n",
      "Video file path: 7HcYJKMxpcg_20_28.avi\n",
      "Ground truth caption: A lion is walking in the cage.\n",
      "Generated caption: a boy is a a a\n",
      "Video file path: CGllPWAwmUo_1_15.avi\n",
      "Ground truth caption: A man is fiddling on a rooftop.\n",
      "Generated caption: a monkey is a a a\n",
      "Video file path: WTf5EgVY5uU_124_128.avi\n",
      "Ground truth caption: The lady added the onions to the oil in the pan.\n",
      "Generated caption: a woman is adding a\n"
     ]
    }
   ],
   "source": [
    "output_file = 'generated_output.txt'\n",
    "\n",
    "generated_cap=[]\n",
    "with open(output_file, 'w') as file:\n",
    "    with torch.no_grad():\n",
    "        for i, (test_video_features, _) in enumerate(test_data_loader):\n",
    "\n",
    "            test_video_features = test_video_features.to(device)\n",
    "            #print(f\"Shape of video features before passing to generate_caption: {test_video_features.shape}\")\n",
    "\n",
    "            generated_caption = generate_caption(model, test_video_features, vocab, max_length)\n",
    "            generated_cap.append(generated_caption)\n",
    "            #print(generated_cap)\n",
    "\n",
    "            # ground truth for printing\n",
    "            ground_truth_captions = test_annotations[i]['caption']\n",
    "            random_index = np.random.randint(0, len(ground_truth_captions))\n",
    "            ground_truth_caption = ground_truth_captions[random_index]\n",
    "\n",
    "            video_file_path = test_annotations[i]['id']\n",
    "            file.write(f\"{video_file_path}, {generated_caption}\\n\")\n",
    "\n",
    "            print(f\"Video file path: {video_file_path}\")\n",
    "            print(f\"Ground truth caption: {ground_truth_caption}\")\n",
    "            print(f\"Generated caption: {generated_caption}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a77acd-4b5c-455b-a1a9-5a468a7c67d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f73900-9fd7-47ba-afc5-6b361979a348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
